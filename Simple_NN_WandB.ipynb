{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. use dataset without dummy values\n",
    "2. intergrate W&B + naming of the models so that output differences and model experiments can be in synch. i.e. name example NN_2FC_BCE_SDG_ep100_lr001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "#from tqdm.notebook import tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "#from logger import CheckpointSaver\n",
    "\n",
    "from ml_collections import config_dict\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# custom project utilities\n",
    "from utilities.dataproviderNN import get_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "# Dataloader randomness if num_workers >1 https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "set_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_API_KEY=\"620527a80f5b194ce6ba9498879a2ebe65db428d\"\n",
    "# Name and notes optional\n",
    "WANDB_NAME=\"My first run\"\n",
    "WANDB_NOTES=\"Smaller learning rate, more regularization.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmakcfd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"620527a80f5b194ce6ba9498879a2ebe65db428d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config_dict.ConfigDict()\n",
    "cfg.epochs = 10\n",
    "cfg.batch_size = 32\n",
    "cfg.lr = 1e-3\n",
    "cfg.dropout = random.uniform(0.01, 0.80)\n",
    "cfg.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20230711_131210-3pc049yk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/makcfd/thesis-test/runs/3pc049yk' target=\"_blank\">experiment 12</a></strong> to <a href='https://wandb.ai/makcfd/thesis-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/makcfd/thesis-test' target=\"_blank\">https://wandb.ai/makcfd/thesis-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/makcfd/thesis-test/runs/3pc049yk' target=\"_blank\">https://wandb.ai/makcfd/thesis-test/runs/3pc049yk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"thesis-test\", \n",
    "    config=cfg.to_dict(),\n",
    "    name=\"experiment 12\",)\n",
    "# batch_size = 1000\n",
    "# num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, criterion, train_data_loader, optimizer, epoch, device='cuda'):\n",
    "    model.train()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(train_data_loader, desc=\"Epoch\" + \" [TRAIN] \" + str(epoch + 1))\n",
    "\n",
    "    for t, data in enumerate(tk):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        labels = labels.float()\n",
    "        #labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        fin_loss += loss.item()\n",
    "        tk.set_postfix(\n",
    "            {\n",
    "                \"loss\": \"%.6f\" % float(fin_loss / (t + 1)),\n",
    "                \"LR\": optimizer.param_groups[0][\"lr\"],\n",
    "            }\n",
    "        )\n",
    "    return fin_loss / len(train_data_loader), optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, criterion, eval_data_loader, epoch, device='cuda'):\n",
    "    model.eval()\n",
    "    fin_loss = 0.0\n",
    "    tk = tqdm(eval_data_loader, desc=\"Epoch\" + \" [VALID] \" + str(epoch + 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t, data in enumerate(tk):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.float()\n",
    "            #labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            fin_loss += loss.item()\n",
    "            tk.set_postfix({\"loss\": \"%.6f\" % float(fin_loss / (t + 1))})\n",
    "        return fin_loss / len(eval_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & Orderred dict add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = config_dict.ConfigDict()\n",
    "cfg.epochs = 5\n",
    "cfg.batch_size = 20\n",
    "cfg.lr = 1e-3\n",
    "cfg.dropout = random.uniform(0.01, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think of whether this function will be needed\n",
    "def set_config():\n",
    "    config={\n",
    "        \"learning_rate\": 0.01 + 0.1 * random.random(),\n",
    "        \"batch_size\": 128,\n",
    "        \"architecture\": \"CNN\",\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1', Linear(in_features=10, out_features=10, bias=True)), ('relu1', ReLU()), ('relu2', ReLU()), ('output', Linear(in_features=20, out_features=1, bias=True)), ('softmax', Softmax(dim=1))])\n"
     ]
    }
   ],
   "source": [
    "input_size = 10\n",
    "hidden_sizes = [10,20]\n",
    "output_size = 1\n",
    "blueprint = OrderedDict([('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "             ('relu1', nn.ReLU()),\n",
    "             ('relu2', nn.ReLU()),\n",
    "             ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "             ('softmax', nn.Softmax(dim=1))])\n",
    "print(blueprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a field in the config\n",
    "# later use it to define architecture of the model\n",
    "cfg_field = config_dict.FieldReference(OrderedDict())\n",
    "cfg = config_dict.ConfigDict({\n",
    "    'model': cfg_field,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model = OrderedDict([('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "             ('relu1', nn.ReLU()),\n",
    "             ('relu2', nn.ReLU()),\n",
    "             ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "             ('softmax', nn.Softmax(dim=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (output): Linear(in_features=20, out_features=1, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_test = nn.Sequential(cfg.model)\n",
    "print(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(train_dir, test_dir):\n",
    "    \"\"\"\n",
    "    Function is taking care of:\n",
    "        1. Initial data reading\n",
    "        2. Data loaders preparation\n",
    "        3. Formation of model structure\n",
    "        4. Checkpoint saver init\n",
    "        5. Iteration over epochs\n",
    "        6. Calling training and evaluation\n",
    "    \"\"\"\n",
    "    # batch size can be passed as a secont parameter\n",
    "    trainloader = get_data(train_dir, cfg.batch_size)\n",
    "    testloader = get_data(test_dir, cfg.batch_size)\n",
    "\n",
    "    # model\n",
    "    input_size = testloader.dataset.X.shape[1]\n",
    "    hidden_sizes = [40, 20]\n",
    "    output_size = 1\n",
    "    # TODO: pass dictionary style the model architecture to this function\n",
    "    model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(hidden_sizes[1], output_size),\n",
    "                          nn.Sigmoid())\n",
    "    #model = model.cuda()\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    # optimizer\n",
    "    # TODO: pass optimiser to this function\n",
    "    # TODO: test if optimiser can be passed from config\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "    # checkpoint saver\n",
    "    checkpoint_saver = CheckpointSaver(dirpath='./model_weights', decreasing=True, top_n=5)\n",
    "    for epoch in range(cfg.epochs):\n",
    "        avg_loss_train, cfg.lr = train_fn(\n",
    "            model, criterion, trainloader, optimizer, epoch, device=device\n",
    "        )\n",
    "        avg_loss_eval = eval_fn(model, criterion, testloader, epoch, device=device)\n",
    "        checkpoint_saver(model, epoch, avg_loss_eval)\n",
    "        wandb.run.log({'epoch': epoch, 'train loss': avg_loss_train, 'eval loss': avg_loss_eval})\n",
    "        print(\n",
    "            f\"EPOCH = {epoch} | TRAIN_LOSS = {avg_loss_train} | EVAL_LOSS = {avg_loss_eval}\"\n",
    "        )\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointSaver:\n",
    "    def __init__(self, dirpath, decreasing=True, top_n=5):\n",
    "        \"\"\"\n",
    "        dirpath: Directory path where to store all model weights \n",
    "        decreasing: If decreasing is `True`, then lower metric is better\n",
    "        top_n: Total number of models to track based on validation metric value\n",
    "        \"\"\"\n",
    "        if not os.path.exists(dirpath): os.makedirs(dirpath)\n",
    "        self.dirpath = dirpath\n",
    "        self.top_n = top_n \n",
    "        self.decreasing = decreasing\n",
    "        self.top_model_paths = []\n",
    "        self.best_metric_val = np.Inf if decreasing else -np.Inf\n",
    "        \n",
    "    # add to this function metadata parameter and pass it to artefact\n",
    "    def __call__(self, model, epoch, metric_val):\n",
    "        model_path = os.path.join(self.dirpath, model.__class__.__name__ + f'_epoch{epoch}.pt')\n",
    "        save = metric_val<self.best_metric_val if self.decreasing else metric_val>self.best_metric_val\n",
    "        if save: \n",
    "            logging.info(f\"Current metric value better than {metric_val} better than best {self.best_metric_val}, saving model at {model_path}, & logging model weights to W&B.\")\n",
    "            self.best_metric_val = metric_val\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            # save file in W&B in run\n",
    "            self.log_artifact(f'model-ckpt-epoch-{epoch}.pt', model_path, metric_val)\n",
    "            self.top_model_paths.append({'path': model_path, 'score': metric_val})\n",
    "            self.top_model_paths = sorted(self.top_model_paths, key=lambda o: o['score'], reverse=not self.decreasing)\n",
    "        if len(self.top_model_paths)>self.top_n: \n",
    "            self.cleanup()\n",
    "    \n",
    "    def log_artifact(self, filename, model_path, metric_val):\n",
    "        artifact = wandb.Artifact(filename, type='model', metadata={'Validation score': metric_val})\n",
    "        artifact.add_file(model_path)\n",
    "        wandb.run.log_artifact(artifact)        \n",
    "    \n",
    "    def cleanup(self):\n",
    "        to_remove = self.top_model_paths[self.top_n:]\n",
    "        logging.info(f\"Removing extra models.. {to_remove}\")\n",
    "        for o in to_remove:\n",
    "            os.remove(o['path'])\n",
    "        self.top_model_paths = self.top_model_paths[:self.top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 1: 100%|██████████| 1220/1220 [00:01<00:00, 779.36it/s, loss=0.828123, LR=0.001]\n",
      "Epoch [VALID] 1: 100%|██████████| 305/305 [00:00<00:00, 1365.60it/s, loss=0.374784]\n",
      "INFO:root:Current metric value better than 0.37478437599588615 better than best inf, saving model at ./model_weights/Sequential_epoch0.pt, & logging model weights to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 0 | TRAIN_LOSS = 0.8281234100338866 | EVAL_LOSS = 0.37478437599588615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 2: 100%|██████████| 1220/1220 [00:01<00:00, 793.77it/s, loss=0.746683, LR=0.001]\n",
      "Epoch [VALID] 2: 100%|██████████| 305/305 [00:00<00:00, 1357.08it/s, loss=0.339756]\n",
      "INFO:root:Current metric value better than 0.3397562521402953 better than best 0.37478437599588615, saving model at ./model_weights/Sequential_epoch1.pt, & logging model weights to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 1 | TRAIN_LOSS = 0.7466834224455181 | EVAL_LOSS = 0.3397562521402953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 3: 100%|██████████| 1220/1220 [00:01<00:00, 741.95it/s, loss=0.374689, LR=0.001]\n",
      "Epoch [VALID] 3: 100%|██████████| 305/305 [00:00<00:00, 1359.83it/s, loss=0.336379]\n",
      "INFO:root:Current metric value better than 0.3363785723926591 better than best 0.3397562521402953, saving model at ./model_weights/Sequential_epoch2.pt, & logging model weights to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 2 | TRAIN_LOSS = 0.37468893240343354 | EVAL_LOSS = 0.3363785723926591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 4: 100%|██████████| 1220/1220 [00:01<00:00, 790.93it/s, loss=0.363675, LR=0.001]\n",
      "Epoch [VALID] 4: 100%|██████████| 305/305 [00:00<00:00, 1408.69it/s, loss=0.351333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 3 | TRAIN_LOSS = 0.3636750998250285 | EVAL_LOSS = 0.3513326693509446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 5: 100%|██████████| 1220/1220 [00:01<00:00, 829.53it/s, loss=0.359889, LR=0.001]\n",
      "Epoch [VALID] 5: 100%|██████████| 305/305 [00:00<00:00, 1357.75it/s, loss=0.343874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 4 | TRAIN_LOSS = 0.35988859918396005 | EVAL_LOSS = 0.34387383182517817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 6: 100%|██████████| 1220/1220 [00:01<00:00, 810.93it/s, loss=0.356663, LR=0.001]\n",
      "Epoch [VALID] 6: 100%|██████████| 305/305 [00:00<00:00, 1351.89it/s, loss=0.331032]\n",
      "INFO:root:Current metric value better than 0.3310323763089102 better than best 0.3363785723926591, saving model at ./model_weights/Sequential_epoch5.pt, & logging model weights to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 5 | TRAIN_LOSS = 0.35666324664823346 | EVAL_LOSS = 0.3310323763089102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 7: 100%|██████████| 1220/1220 [00:01<00:00, 853.15it/s, loss=0.354081, LR=0.001]\n",
      "Epoch [VALID] 7: 100%|██████████| 305/305 [00:00<00:00, 1195.89it/s, loss=0.330163]\n",
      "INFO:root:Current metric value better than 0.33016337246679867 better than best 0.3310323763089102, saving model at ./model_weights/Sequential_epoch6.pt, & logging model weights to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 6 | TRAIN_LOSS = 0.3540808026724663 | EVAL_LOSS = 0.33016337246679867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 8: 100%|██████████| 1220/1220 [00:01<00:00, 780.02it/s, loss=0.351603, LR=0.001]\n",
      "Epoch [VALID] 8: 100%|██████████| 305/305 [00:00<00:00, 1342.68it/s, loss=0.338636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 7 | TRAIN_LOSS = 0.35160297027743254 | EVAL_LOSS = 0.33863636716955997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 9: 100%|██████████| 1220/1220 [00:01<00:00, 832.14it/s, loss=0.347569, LR=0.001]\n",
      "Epoch [VALID] 9: 100%|██████████| 305/305 [00:00<00:00, 1359.84it/s, loss=0.325137]\n",
      "INFO:root:Current metric value better than 0.32513716728960884 better than best 0.33016337246679867, saving model at ./model_weights/Sequential_epoch8.pt, & logging model weights to W&B.\n",
      "INFO:root:Removing extra models.. [{'path': './model_weights/Sequential_epoch0.pt', 'score': 0.37478437599588615}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 8 | TRAIN_LOSS = 0.3475687072352796 | EVAL_LOSS = 0.32513716728960884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [TRAIN] 10: 100%|██████████| 1220/1220 [00:01<00:00, 813.10it/s, loss=0.339047, LR=0.001]\n",
      "Epoch [VALID] 10: 100%|██████████| 305/305 [00:00<00:00, 1369.08it/s, loss=0.323423]\n",
      "INFO:root:Current metric value better than 0.3234234699948889 better than best 0.32513716728960884, saving model at ./model_weights/Sequential_epoch9.pt, & logging model weights to W&B.\n",
      "INFO:root:Removing extra models.. [{'path': './model_weights/Sequential_epoch1.pt', 'score': 0.3397562521402953}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH = 9 | TRAIN_LOSS = 0.33904684608588453 | EVAL_LOSS = 0.3234234699948889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>eval loss</td><td>█▃▃▅▄▂▂▃▁▁</td></tr><tr><td>train loss</td><td>█▇▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>eval loss</td><td>0.32342</td></tr><tr><td>train loss</td><td>0.33905</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment 12</strong> at: <a href='https://wandb.ai/makcfd/thesis-test/runs/3pc049yk' target=\"_blank\">https://wandb.ai/makcfd/thesis-test/runs/3pc049yk</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code></code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#criterion = nn.BCELoss()\n",
    "#optimizer = torch.optim.SGD(clf.parameters(),lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(clf.parameters(),lr=learning_rate)\n",
    "\n",
    "train_dir = \"exploiting_model_multiplicity/data/adult_dataset/train/\"\n",
    "test_dir = \"exploiting_model_multiplicity/data/adult_dataset/test/\"\n",
    "run_train(train_dir, test_dir) \n",
    "# or may be pass one path ? /exploiting_model_multiplicity/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
