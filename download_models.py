import argparse
import os

import pandas as pd

import wandb
from my_utilities.config_reader import read_config


BASE_PATH = "/exploiting_model_multiplicity/models"
FILE_SUFFIX = ".csv"


def _download_models(api, path_save: str, project: str, multimodel: list) -> str:
    """
    Downloads models into the defined directory.
    Inputs:
        - multimodel: dictionary where keys are names of artifacts
        - path_to_save: directory where models will be saved
    Outputs:
        - path where downloaded models are saved
    """

    # path_to_save = os.path.join(BASE_PATH, project)
    # if not os.path.exists(path_to_save):
    #     os.makedirs(path_to_save)
    count = 0
    for model_name in multimodel:
        try:
            artifact = api.artifact(f"makcfd/{project}/{model_name}")
            artifact.download(root=path_save)
            count += 1
        except ValueError:
            print("There is no artifact with such a name :(")

        finally:
            print(f"Downloaded artifacts: {count} , name: {model_name}")
    return path_save


def get_filtered_candidates(path_to_filtered_csv: str):
    metadata = pd.read_csv(path_to_filtered_csv)
    return [i + ":v0" for i in metadata["Unnamed: 0"]]


def download_filtered_models():
    key = "620527a80f5b194ce6ba9498879a2ebe65db428d"
    api = wandb.Api(api_key=key)

    parser = argparse.ArgumentParser(
        description="Getting trained modes from the experiment"
    )
    parser.add_argument(
        "--config",
        help="Config/Experiment name",
        type=str,
        default=None,
    )
    args = parser.parse_args()
    config = read_config(args.config)

    dataset_name = config.get("parameters").get("dataset").get("value")
    project_name = config.get("project")
    path_read = os.path.join(
        BASE_PATH,
        dataset_name,
        project_name,
        "metadata",
        "all_models_filtered" + FILE_SUFFIX,
    )
    # path_save = f"/exploiting_model_multiplicity/models/{project_name}/metadata/{project_name}_filtered.csv"
    path_save = os.path.join(
        BASE_PATH,
        dataset_name,
        project_name,
    )

    if not os.path.exists(path_save):
        os.makedirs(path_save)
    candidates = get_filtered_candidates(path_read)

    _download_models(
        api,
        path_save,
        project=project_name,
        multimodel=candidates,
    )


download_filtered_models()
