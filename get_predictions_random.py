import argparse
import os

import pandas as pd
import torch
import tqdm
from torch import backends, cuda, no_grad

from my_utilities.config_reader import read_config
from my_utilities.dataproviderNN import get_data

# CONST VARIABLES
DATASET_PATH = "/exploiting_model_multiplicity/data/"
BASEDIR_MODELS = "/exploiting_model_multiplicity/models/"
BASEDIR_PREDICTIONS = "/exploiting_model_multiplicity/experiment_results/"
FILE_SUFFIX = ".csv"


# device = (
#     "cuda" if cuda.is_available() else "mps" if backends.mps.is_available() else "cpu"
# )


def _save_results(models: list, index: list, predictions: list):
    df = pd.DataFrame(predictions, columns=models, index=index)
    return df


def get_downloaded_models(project_name: str) -> list:
    # Unnamed: 0
    path_results = os.path.join(
        BASEDIR_MODELS,
        project_name,
        "metadata",
        project_name + "_filtered" + FILE_SUFFIX,
    )
    models_filtered = pd.read_csv(path_results)
    models_names = [i.split(":")[0] for i in models_filtered["Unnamed: 0"].values]
    # Walk through the folder and its subfolders
    # print("models names:", models_names)
    models = []
    for root, dirs, files in os.walk(BASEDIR_MODELS):
        for file in files:
            if (
                project_name in root
                and not file.endswith(".csv")
                and file in models_names
            ):
                path = os.path.join(root, file)
                models.append(path)
    return models


def get_predictions(args):
    # TODO 4: define predictrion size as a parameter
    predictions_size = args.samples
    config = read_config(args.config)
    dataset_name = config.get("parameters").get("dataset").get("value")
    project_name = config.get("project")
    test_dir = DATASET_PATH + f"{dataset_name}" + "/" + "test/"
    testloader = get_data(
        test_dir,
        batch_size=1,
        random=True,
        size=predictions_size,
        seed_value=42,
    )

    list_of_models = get_downloaded_models(project_name=project_name)
    idx = []
    predictions = []
    # get models names to use it as index in dataframe at the end
    models_index = [path.split("/")[-1] for path in list_of_models]
    # print("models index use as COLUMNS: ", models_index)
    predicted = 0
    for data in testloader:
        print(f"item {predicted} is being processed")
        predicted += 1
        inputs, labels, index = data
        # print("len inputs: ", len(inputs))
        # print("labels: ", labels)
        # print("index: ", index)
        idx.append(index.item())
        model_prediction = []
        for model_path in list_of_models:
            # print(f"model loaded from path {model_path}")
            model = torch.jit.load(model_path)
            model.eval()
            cuda.empty_cache()
            device = (
                "cuda"
                if cuda.is_available()
                else "mps"
                if backends.mps.is_available()
                else "cpu"
            )
            inputs, labels = inputs.to(device), labels.to(device)
            with no_grad():
                # for t, data in enumerate(tk):
                # TODO-3 May be parallel here for all models? not for one?
                outputs = model(inputs)
                pred_proba = outputs.item()
                pred_proba = round(pred_proba, 4)
                model_prediction.append(pred_proba)
        predictions.append(model_prediction)

    df = _save_results(models_index, idx, predictions)
    base_path_to_save = os.path.join(BASEDIR_PREDICTIONS, project_name)
    if not os.path.exists(base_path_to_save):
        os.makedirs(base_path_to_save)
    # path_to_save = path_to_save + f"_{predictions_size}.csv"
    # print(path_to_save)
    df.to_csv(base_path_to_save + f"/{predictions_size}.csv", index=True)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Getting predictions for the experiment"
    )
    parser.add_argument(
        "--config", help="Config/Experiment name", type=str, default=None
    )
    parser.add_argument(
        "--samples", help="Number of observations", type=int, default=10
    )
    args = parser.parse_args()
    get_predictions(args)
