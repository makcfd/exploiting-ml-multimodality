import pandas as pd
import numpy as np
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch


class Data(Dataset):
    def __init__(self, X, y):
        # need to convert float64 to float32 else
        # will get the following error
        # RuntimeError: expected scalar type Double but found Float
        self.index = X.index.values
        X = X.values
        y = y.values
        self.X = torch.from_numpy(X.astype(np.float32))
        # need to convert float64 to Long else
        # will get the following error
        # RuntimeError: expected scalar type Long but found Float
        self.y = torch.from_numpy(y).type(torch.LongTensor)
        self.len = self.X.shape[0]

    def __getitem__(self, index):
        # idx = index
        ix = self.X[index]
        iy = self.y[index]
        idx = self.index[index]
        return self.X[index], self.y[index], self.index[index]

    def __len__(self):
        return self.len


def get_data(
    directory: str,
    use_batch: bool = True,
    batch_size: int = 32,
    random: bool = False,
) -> DataLoader:
    print("dataloader received info - use_batch: ", use_batch)
    print("dataloader received info - batch_size: ", batch_size)
    if random:
        df_X = pd.read_csv(directory + "X.csv", index_col=0)
        df_y = pd.read_csv(directory + "Y.csv", index_col=0)
        chosen_idx = np.random.choice(df_X.index.to_list(), replace=False, size=1)
        print("chosen_idx:", chosen_idx)
        X = df_X.loc[chosen_idx]
        y = df_y.loc[chosen_idx]
    else:
        X = pd.read_csv(directory + "X.csv", index_col=0)
        y = pd.read_csv(directory + "Y.csv", index_col=0)
    data = Data(X, y)
    if not use_batch:
        # use this option to predict on full slice of data
        batch_size = data.len
    loader = DataLoader(
        data,
        batch_size=batch_size,
        shuffle=False,
        # num_workers=num_workers,
    )
    return loader


# # # Below is test fixtures for this file
DATASET_PATH = "/exploiting_model_multiplicity/data/"
test_dir = DATASET_PATH + "adult_dataset" + "/" + "test/"
# # test_dir = DATASET_PATH + "adult_dataset" + "/" + "train/"
testloader = get_data(
    test_dir,
    use_batch=True,
    batch_size=6,
    random=False,
)

for data in testloader:
    features, labels, index = data
    print("len index: ", len(index))
    print("index: ", index.flatten())
    print("labels: ", labels.flatten())
# print("values of index: ", index[:1])
# for data in testloader:
#     features, labels, index = data
#     print("lex index in for loop: ", len(index))
#     print("values of index in for loop: ", index[:1])

# df = pd.read_csv(test_dir + "X.csv", index_col=0)
# chosen_idx = np.random.choice(df.index.to_list(), replace=False, size=1)
# print("chosen_idx:", chosen_idx)
# df2 = df.loc[chosen_idx]


# print(df2.index)
