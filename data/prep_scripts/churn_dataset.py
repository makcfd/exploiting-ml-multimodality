import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler


df = pd.read_csv("/exploiting_model_multiplicity/data/original/Churn_Modelling.csv")
df.drop_duplicates(inplace=True)
df.drop(["RowNumber"], axis=1, inplace=True)
df.drop(["CustomerId"], axis=1, inplace=True)
df.drop(["Surname"], axis=1, inplace=True)

df_ml = pd.get_dummies(df, drop_first=True)
numeric = ["CreditScore", "Age", "Balance", "EstimatedSalary"]

features = df_ml.drop(["Exited"], axis=1)
target = df_ml["Exited"]
X_train, X_test, Y_train, Y_test = train_test_split(
    features, target, train_size=0.8, test_size=0.2, random_state=42, shuffle=False
)
scaler_train = StandardScaler()
scaler_train.fit(X_train[numeric])
X_train[numeric] = scaler_train.transform(X_train[numeric])

scaler_test = StandardScaler()
scaler_test.fit(X_test[numeric])
X_test[numeric] = scaler_test.transform(X_test[numeric])

paths_to_save = ["../churn_dataset/train/", "../churn_dataset/test/"]
for path in paths_to_save:
    if not os.path.exists(path):
        os.makedirs(path)
X_train.to_csv("../churn_dataset/train/X.csv", index=True)
Y_train.to_csv("../churn_dataset/train/Y.csv", index=True)
X_test.to_csv("../churn_dataset/test/X.csv", index=True)
Y_test.to_csv("../churn_dataset/test/Y.csv", index=True)
