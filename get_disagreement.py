import os
import pandas as pd
import numpy as np
from pathlib import Path
from torch import cuda, backends, no_grad
import torch
from my_utilities.data_provider_NN import get_data


DATASET_PATH = "/exploiting_model_multiplicity/data/"
BASEDIR_MODELS = "/exploiting_model_multiplicity/models/"
FILE_SUFFIX = ".csv"


def _get_paths(project_name: str, dataset_name: str):
    path_models = os.path.join(
        BASEDIR_MODELS,
        dataset_name,
        project_name,
        "metadata",
        "all_models_filtered" + FILE_SUFFIX,
    )
    test_dir = DATASET_PATH + f"{dataset_name}" + "/" + "test/"

    return path_models, test_dir


def _select_models_samples_replace(df, n_samples=2, n_times=1):
    """
    Randomly select samples from a DataFrame without repetition across all selection attempts.

    Parameters:
    - df (pd.DataFrame): The input DataFrame.
    - n_samples (int): Number of samples to select.
    - n_times (int): Number of times to run the selection process.

    Returns:
    - list of pd.DataFrame: A list containing the selected samples.
    """
    samples_list = []
    for _ in range(n_times):
        samples = df.sample(n=n_samples, replace=True)
        samples_list.append(list(samples.index))
    return samples_list


def _get_predictions(model, dataloader):
    predictions_raw = []
    predictions = []
    y_true = []
    idx = []
    model.eval()
    cuda.empty_cache()
    device = (
        "cuda"
        if cuda.is_available()
        else "mps"
        if backends.mps.is_available()
        else "cpu"
    )
    for data in dataloader:
        inputs, labels, index = data
        idx += index.tolist()
        y_true += labels.flatten().tolist()
        inputs, labels = inputs.to(device), labels.to(device)
        with no_grad():
            outputs = model(inputs)
            python_list_2 = [item[0] for item in outputs.tolist()]
            outputs = outputs.numpy()

            predictions_raw += python_list_2
            python_list = np.where(outputs >= 0.5, 1, 0).flatten().tolist()
            predictions += python_list
    df = pd.DataFrame(
        {"idx": idx, "labels": y_true, "pred_raw": predictions_raw, "pred": predictions}
    )
    return df


def _calc_difference(preidcitons_l, predictions_r):
    difference = abs(preidcitons_l["pred"] - predictions_r["pred"])
    return difference.sum()


def calc_disagreemnt(project_name: str, dataset_name: str, n_times: int = 15):
    filtered_models, test_data = _get_paths(project_name, dataset_name)
    models_filtered = pd.read_csv(filtered_models, index_col="Unnamed: 0")

    disagreements = []
    testloader = get_data(
        test_data,
        batch_size=1000,
        random=False,
    )

    selected_samples = _select_models_samples_replace(
        models_filtered, n_samples=2, n_times=n_times
    )
    path_to_models = os.path.join(BASEDIR_MODELS, dataset_name, project_name)

    for _, sample in enumerate(selected_samples, 1):
        model_l, model_r = sample
        model_l_path = os.path.join(path_to_models, model_l)
        model_r_path = os.path.join(path_to_models, model_r)
        model_l_loaded = torch.jit.load(model_l_path)
        model_r_loaded = torch.jit.load(model_r_path)
        l_predictions = _get_predictions(model_l_loaded, testloader)
        r_predictions = _get_predictions(model_r_loaded, testloader)
        disagreement = _calc_difference(l_predictions, r_predictions)
        disagreements.append(disagreement)
    return disagreements
