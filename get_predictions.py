import argparse
import os
import pandas as pd
import torch
from torch import backends, cuda, no_grad

from my_utilities.config_reader import read_config
from my_utilities.data_provider_NN import get_data

DATASET_PATH = "/exploiting_model_multiplicity/data/"
BASEDIR_MODELS = "/exploiting_model_multiplicity/models/"
BASEDIR_PREDICTIONS = "/exploiting_model_multiplicity/experiment_results/"
FILE_SUFFIX = ".csv"


def _get_df(models: list, index: list, predictions: list):
    df = pd.DataFrame(predictions, columns=models, index=index)
    return df


def _save_results(df, dataset_name, project_name, predictions_size):
    base_path_to_save = os.path.join(BASEDIR_PREDICTIONS, dataset_name, project_name)
    if not os.path.exists(base_path_to_save):
        os.makedirs(base_path_to_save)
    if predictions_size:
        name = predictions_size
    else:
        name = "full"
    df.to_csv(base_path_to_save + f"/{name}.csv", index=True)


def get_downloaded_models(dataset_name: str, project_name: str) -> list:
    # Unnamed: 0
    path_results = os.path.join(
        BASEDIR_MODELS,
        dataset_name,
        project_name,
        "metadata",
        "all_models_filtered" + FILE_SUFFIX,
    )
    models_filtered = pd.read_csv(path_results)
    print("FILTERED MODELS")
    print(len(models_filtered))
    models_names = [i.split(":")[0] for i in models_filtered["Unnamed: 0"].values]
    print("Models selected in function: ", len(models_names))
    models = []
    for root, dirs, files in os.walk(BASEDIR_MODELS + dataset_name):
        for file in files:
            if (
                project_name in root
                and not file.endswith(".csv")
                and file in models_names
            ):
                path = os.path.join(root, file)
                models.append(path)
    return models


def get_predictions_samples(dataloader, list_of_models):
    idx = []
    predictions = []
    print(f"Selected {len(list_of_models)} models")
    models_index = [path.split("/")[-1] for path in list_of_models]
    print(f"Models index {models_index}")
    predicted = 0
    for data in dataloader:
        print(f"item {predicted} is being processed")
        predicted += 1
        inputs, labels, index = data
        idx.append(index.item())
        model_prediction = []
        for model_path in list_of_models:
            print("model_path: ", model_path)
            model = torch.jit.load(model_path)
            model.eval()
            cuda.empty_cache()
            device = (
                "cuda"
                if cuda.is_available()
                else "mps"
                if backends.mps.is_available()
                else "cpu"
            )
            inputs, labels = inputs.to(device), labels.to(device)
            with no_grad():
                outputs = model(inputs)
                pred_proba = outputs.item()
                pred_proba = round(pred_proba, 4)
                model_prediction.append(pred_proba)
        predictions.append(model_prediction)
    df = _get_df(models_index, idx, predictions)
    return df


def get_predictions_full(dataloader, list_of_models):
    df = pd.DataFrame()
    print(f"Selected {len(list_of_models)} models")
    models_index = [path.split("/")[-1] for path in list_of_models]

    device = (
        "cuda"
        if cuda.is_available()
        else "mps"
        if backends.mps.is_available()
        else "cpu"
    )
    for model_path, model_name in zip(list_of_models, models_index):
        predictions = []
        idx = []
        cuda.empty_cache()
        model = torch.jit.load(model_path)
        model.eval()
        for data in dataloader:
            inputs, labels, index = data
            inputs, labels = inputs.to(device), labels.to(device)
            idx += index.tolist()
            with no_grad():
                outputs = model(inputs)
                python_list_2 = [item[0] for item in outputs.tolist()]
                outputs = outputs.numpy()
                predictions += python_list_2

        df["index"] = idx
        df[model_name] = predictions
    return df


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Getting predictions for the experiment"
    )
    parser.add_argument(
        "--config", help="Config/Experiment name", type=str, default=None
    )
    parser.add_argument(
        "--samples", help="Number of observations", type=int, default=None
    )
    args = parser.parse_args()
    predictions_size = args.samples
    config = read_config(args.config)
    dataset_name = config.get("parameters").get("dataset").get("value")
    project_name = config.get("project")
    test_dir = DATASET_PATH + f"{dataset_name}" + "/" + "test/"
    print(f"For {dataset_name} of experiment {project_name} predictions started.")
    if predictions_size:
        dataloader = get_data(
            test_dir,
            batch_size=1,
            random=True,
            size=predictions_size,
        )
    else:
        dataloader = get_data(
            test_dir,
            batch_size=500,
        )
    list_of_models = get_downloaded_models(dataset_name, project_name)
    print("FUNCTION RESULT len: ", len(list_of_models))
    if predictions_size:
        df = get_predictions_samples(dataloader, list_of_models)
    else:
        df = get_predictions_full(dataloader, list_of_models)
    print("Resulting df shape: ", df.shape)
    _save_results(df, dataset_name, project_name, predictions_size)
